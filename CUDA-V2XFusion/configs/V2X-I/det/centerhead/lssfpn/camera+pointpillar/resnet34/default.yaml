model:
  encoders:
    camera:
      backbone:
        type: ResNet
        depth: 34
        out_indices: [1, 2, 3]
        init_cfg:
          type: Pretrained
          checkpoint: https://download.pytorch.org/models/resnet34-333f7ec4.pth
      neck:
        type: GeneralizedLSSFPN
        in_channels: [128, 256, 512]
        out_channels: 256
        start_level: 0
        num_outs: 3
        norm_cfg:
          type: BN2d
          requires_grad: true
        act_cfg:
          type: ReLU
          inplace: true
        upsample_cfg:
          mode: bilinear
          align_corners: false      
      vtransform:
        in_channels: 256
        out_channels: 80
        feature_size: ${[image_size[0] // 16, image_size[1] // 16]}
        xbound: [0, 102.4, 0.8]
        ybound: [-51.2, 51.2, 0.8]
        zbound: [-5, 3, 8]
        dbound: [-2.0, 0.0, 90]
        downsample: 1
  decoder:
    backbone:
      type: GeneralizedResNet
      in_channels: 80
      blocks:
        - [2, 128, 2]
        - [2, 256, 2]
        - [2, 512, 1]
    neck:
      type: LSSFPN
      in_indices: [-1, 0]
      in_channels: [512, 128]
      out_channels: 256
      scale_factor: 2

  fuser:
    type: ConvFuser
    in_channels: [80, 64]
    out_channels: 80

optimizer:
  paramwise_cfg:
    custom_keys:
      absolute_pos_embed:
        decay_mult: 0
      relative_position_bias_table:
        decay_mult: 0
      encoders.camera.backbone:
        lr_mult: 0.1


lr_config:
  policy: cyclic
  target_ratio: 5.0
  cyclic_times: 1
  step_ratio_up: 0.4

momentum_config:
  policy: cyclic
  cyclic_times: 1
  step_ratio_up: 0.4

data:
  samples_per_gpu: 6
  workers_per_gpu: 6


